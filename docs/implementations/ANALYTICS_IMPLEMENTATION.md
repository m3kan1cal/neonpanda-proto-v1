## Weekly Analytics Pipeline Architecture

### Phase 1: Trigger & Data Collection (Sunday 6:00 AM UTC) âœ… COMPLETE

```yaml
1. CloudWatch Event Trigger âœ… IMPLEMENTED
   - Cron expression: "0 6 ? * SUN *" âœ…
   - Targets: Lambda function (build-weekly-analytics) âœ…
   - Retry policy: 2 retries with exponential backoff âœ…

2. Lambda: build-weekly-analytics âœ… IMPLEMENTED
   - Query all active users from DynamoDB (users table) âœ…
   - Process users in batches of 50 for efficiency âœ…
   - Direct DynamoDB queries (no SQS overhead) âœ…
   - Built-in retry logic for failed processing âœ…
   - Skip users with < 2 workouts that week ğŸ”„ TODO
```

**Implementation Details:**
- **EventBridge Schedule**: `cron(0 6 ? * 1 *)` in `build-weekly-analytics/resource.ts`
- **GSI-3 User Queries**: `queryAllUsers()` using `entityType='user'` with pagination
- **Batch Processing**: 50 users per batch with `exclusiveStartKey` pagination
- **Error Handling**: Per-user and global try/catch with detailed logging
- **Memory**: 1024MB, 15min timeout for processing all users
- **Missing**: Workout count filtering logic (marked as TODO in handler)

### Phase 2: Data Aggregation (Per User) âœ… COMPLETE

```yaml
4. Fetch Current Week Data âœ… IMPLEMENTED
   - Query DynamoDB (workouts table) âœ…
   - Filter: user_id AND date BETWEEN week_start AND week_end âœ…
   - Get all workouts in UWS format (already extracted) âœ…
   - Include: completed workouts, skipped workouts, modifications âœ…

5. Fetch Historical Context âœ… IMPLEMENTED
   - Previous 4 weeks of workout summaries (for trending) âœ…
   - Query pattern: user_id AND date BETWEEN (week_start - 28) AND week_end âœ…
   - Extract existing AI-generated summaries (no aggregation needed) âœ…

6. Fetch Coaching Context âœ… IMPLEMENTED
   - Query DynamoDB (conversations table) âœ…
   - Get last 2 weeks of coach-athlete messages âœ…
   - Extract: technical cues, feedback, goals discussed âœ…
   - Summarize using Claude Haiku (fast/cheap) if > 1000 words ğŸ”„ TODO

7. Fetch User Context âœ… IMPLEMENTED
   - Query DynamoDB (user_memories table) âœ…
   - Get: injuries, goals, PRs, equipment access, schedule constraints âœ…
   - Include: athlete profile (training age, competition dates) âœ…
   - Recent check-ins or subjective feedback âœ…

8. Fetch Program Context ğŸ”„ SKIPPED (as requested)
   - Query DynamoDB (programs table)
   - Get current program template/methodology
   - Include: phase, week number, intended stimulus
   - Planned vs completed for adherence metrics
```

**Implementation Details:**
- **Data Fetching Library**: `amplify/functions/libs/analytics/data-fetching.ts`
- **Week Calculations**: `getCurrentWeekRange()`, `getLastNWeeksRange()` for date filtering
- **Parallel Data Fetching**: All user data (workouts, conversations, memories) fetched simultaneously
- **Query â†’ Detail Pattern**: Use simplified list queries then fetch full details for each item
- **Message Filtering**: Coaching conversations filtered to last 2 weeks of messages only
- **Error Isolation**: Individual data fetch failures don't stop overall user processing
- **Comprehensive Logging**: Detailed metrics for workouts, conversations, memories, and historical summaries per user
- **Early Filtering**: Users with < 2 workouts skipped before expensive data aggregation
- **Historical Summaries**: Leverages existing AI-generated workout summaries (4 weeks, ~8KB vs 56KB raw data)
- **Summary Quality Filter**: Only includes historical workouts with substantial summaries (>50 characters)

### Phase 3: LLM Analytics Processing âœ… COMPLETE

```yaml
9. Construct Analytics Prompt âœ… IMPLEMENTED
   - Combine all context into structured prompt âœ…
   - Format:
     * Athlete context (AI profile + memories) âœ…
     * Current week UWS data âœ…
     * Previous weeks summary âœ…
     * Coaching conversations summary âœ…
     * Program context ğŸ”„ SKIPPED (not built yet)
   - Add system prompt with output format requirements âœ…

10. Call Claude via Bedrock âœ… IMPLEMENTED
   - Model: claude-3-5-sonnet-4 (Sonnet 4 with thinking) âœ…
   - Max tokens: Default Bedrock limits âœ…
   - Temperature: Default (for consistency) âœ…
   - Retry logic: Basic error handling with log and continue âœ…
   - Fallback: Log error and continue processing other users âœ…

11. Process LLM Response âœ… IMPLEMENTED
   - Parse JSON response âœ…
   - Validate structure against schema (basic JSON parsing) âœ…
   - Handle any parsing errors gracefully âœ…
   - Log complete analytics output for prototype âœ…
```

**Implementation Details:**
- **Analytics Generation**: `generateAnalytics()` function in `data-fetching.ts`
- **Enhanced Athlete Context**: Combines AI-generated athlete profile with structured user memories
- **Comprehensive Prompt**: Enhanced with athlete context, coaching conversations, historical summaries
- **Claude Thinking Enabled**: Uses same thinking pattern as workout extraction/normalization
- **Error Isolation**: Analytics failures don't stop batch processing
- **Prototype Logging**: Complete JSON analytics output logged for review
- **Integration**: Seamlessly integrated into `processBatch()` workflow

### Phase 4: Storage & Notification

```yaml
12. Store Analytics Results âœ… COMPLETED
   Primary Storage (DynamoDB - existing table): âœ… IMPLEMENTED
   - EntityType: "analytics"
   - Partition Key: user#${user_id}
   - Sort Key: weeklyAnalytics#${week_id} (YYYY-WW)
   - Includes S3 location reference
   - Implementation: saveWeeklyAnalytics() in operations.ts

   Secondary Storage (S3): âœ… IMPLEMENTED
   - Path: analytics/weekly-analytics/
   - Includes metadata and complete analytics JSON
   - Dual storage ensures data availability and queryability

13. Generate Quick Insights ğŸ”® FUTURE ENHANCEMENT
   - Extract top 3 insights from LLM output
   - Create notification-friendly summary
   - Generate trend indicators (â†‘â†“â†’)

14. Update User Dashboard Cache ğŸ”® FUTURE ENHANCEMENT
   - Write to DynamoDB (dashboard_cache)
   - Pre-calculate:
     * Week-over-week changes
     * Achievement badges
     * Progress charts data
   - Set cache expiry: 1 week

15. Send Notifications ğŸ”® FUTURE ENHANCEMENT
   In-App (Phase 1):
   - Write to DynamoDB (notifications table)
   - Set badge/counter in user session

   Email/Push (Phase 2 - add later):
   - Email (via SES): Template with top insights, link to dashboard
   - Push (via SNS): Title + body with top insight + metric
```

### Phase 5: Frontend Dashboard Display âš ï¸ PARTIALLY IMPLEMENTED

```yaml
16. Frontend Data Fetching âš ï¸ PARTIAL
   React Dashboard requests:
   - CURRENT (PARTIAL âš ï¸):
     * GET /users/{userId}/reports/weekly (list) âœ…
     * GET /users/{userId}/reports/weekly/{weekId} (single) âœ…
     * Uses pre-computed weekly analytics stored in DynamoDB/S3 âœ…
     * dashboard_cache layer âŒ
   - FUTURE:
     * GET /api/analytics/current-week âŒ
     * Check dashboard_cache first âŒ
     * Fall back to analytics_results âŒ
     * Return immediately (pre-computed) âŒ

17. Dashboard Components âš ï¸ PARTIAL
   - CURRENT (PARTIAL âš ï¸):
     * Weekly Report Viewer (formatted + raw toggle) âœ…
     * AI Insights Panel (human_summary) âœ…
     * Data Quality (analysis_confidence, data_completeness) âœ…
   - FUTURE:
     * Weekly Summary Card (hero metrics) âŒ
     * Volume Chart (daily/weekly trends) âŒ
     * Movement Heatmap (frequency/volume by exercise) âŒ
     * PR Tracker (new records highlighted) âŒ
     * Week-over-week Comparison âŒ

18. Interactive Features âŒ NOT IMPLEMENTED
   - FUTURE:
     * Click any metric for detailed breakdown âŒ
     * Export to PDF report âŒ
     * Share achievements to social âŒ
     * Compare to previous weeks âŒ
     * Add coach comments/responses âŒ
```

**Phase 5 Implementation Details (current)**
- Frontend routing: `/training-grounds/reports/weekly?userId=...&weekId=...`
- Components: `WeeklyReports.jsx`, `WeeklyReportViewer.jsx`
- API util: `src/utils/apis/reportApi.js` (list + single)
- Agent: `src/utils/agents/ReportAgent.js` (state management, loading, errors)
- TrainingGrounds integration: â€œReports & Insightsâ€ section with recent reports list and navigation

Status summary:
- 16. Frontend Data Fetching: PARTIAL
- 17. Dashboard Components: PARTIAL (basic viewer + insights + data quality)
- 18. Interactive Features: FUTURE

### Phase 6: Error Handling & Monitoring âš ï¸ PARTIALLY IMPLEMENTED (~60%)

```yaml
19. Error Handling
   Failed LLM calls:
   - Retry with exponential backoff ğŸ”® FUTURE ENHANCEMENT
   - Fallback to basic statistical analysis ğŸ”® FUTURE ENHANCEMENT
   - Notify admin if persistent failures ğŸ”® FUTURE ENHANCEMENT

   Missing data: âœ… IMPLEMENTED
   - Process with available data âœ… (skip users < 2 workouts, handle missing historical)
   - Flag incompleteness in results âœ… (data quality metadata)
   - Suggest what user should track ğŸ”® FUTURE ENHANCEMENT

   Invalid responses: âœ… IMPLEMENTED
   - Log to CloudWatch âœ… (console.error logging)
   - Send to DLQ for manual review ğŸ”® FUTURE ENHANCEMENT
   - Provide generic insights as fallback âœ… (JSON parsing fallbacks, normalization)

20. Monitoring & Alerting ğŸ”® FUTURE ENHANCEMENT
   CloudWatch Dashboards:
   - Processing success rate
   - Average processing time
   - LLM token usage and costs
   - User engagement with analytics

   Alarms:
   - Failed processing > 5%
   - Processing time > 5 minutes
   - LLM costs > budget threshold
   - No analytics generated for active users
```

### System Architecture Diagram

```
[CloudWatch Event]
    â†“ (Sunday 6am)
[Lambda: weekly-analytics] â†’ [DynamoDB: Workouts]
    â†“                        [DynamoDB: Conversations]
    â†“                        [DynamoDB: Memories]
    â†“
[Construct Prompt]
    â†“
[Amazon Bedrock: Claude Opus]
    â†“
[Parse & Validate]
    â†“
[DynamoDB: Analytics] â†’ [S3: Archive (Phase 2)]
    â†“
[Cache Layer]
    â†“
[Notifications] â†’ [In-App (Phase 1)]
                â†’ [Email/Push (Phase 2)]
    â†“
[React Dashboard]
```

### Cost Optimization Strategies

1. **Batch Processing**: Process users in batches to reduce Lambda cold starts
2. **Caching**: Cache previous weeks' summaries to avoid reprocessing
3. **Tiered Processing**: Use Haiku for summarization, Opus only for final analytics
4. **Smart Querying**: Use DynamoDB query instead of scan, proper indexes
5. **Conditional Analytics**: Skip if user had < 2 workouts that week

### Scaling Considerations

- **Rate Limiting**: Limit concurrent Bedrock calls to avoid throttling
- **Queue Management**: Use SQS batch processing for efficiency
- **Regional Deployment**: Process users in their regional Bedrock endpoint
- **Progressive Rollout**: Start with power users, expand gradually
